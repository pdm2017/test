{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train2.csv\")\n",
    "test = pd.read_csv(\"../data/test2.csv\")\n",
    "test_temp = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train, pred_test, tar_train, tar_test = train_test_split(train[list(test.columns)], train[\"Survived\"], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelAccuracy(model):\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(train[list(test.columns)], train[\"Survived\"], test_size = 0.2)\n",
    "    \n",
    "    if model == \"NaiveBayes\":\n",
    "        classifier = GaussianNB()\n",
    "    elif model == \"RandomForest\":\n",
    "        classifier = RandomForestClassifier(n_estimators = 100)\n",
    "    elif model == \"DecisionTree\":\n",
    "        classifier = DecisionTreeClassifier(random_state = 100)\n",
    "    elif model == \"XGBoost\":\n",
    "        classifier = XGBClassifier()\n",
    "    elif model == \"LogisticRegression\":\n",
    "        classifier = LogisticRegression(solver = \"lbfgs\", max_iter = 700)\n",
    "    elif model == \"SVM\":\n",
    "        classifier = SVC(gamma = \"scale\")\n",
    "    elif model == \"KNeighborsClassifier\":\n",
    "        classifier = KNeighborsClassifier(p = 2, n_neighbors = 10)\n",
    "    elif model == \"GradientBoost\":\n",
    "        classifier = GradientBoostingClassifier(n_estimators = 7, learning_rate = 1.1)\n",
    "    elif model == \"AdaBoost\":\n",
    "        classifier = AdaBoostClassifier(n_estimators = 50, learning_rate = 1)\n",
    "\n",
    "    classifier.fit(pred_train, tar_train)\n",
    "    prediction = classifier.predict(pred_test)\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(tar_test, prediction)\n",
    "    accuracy = sklearn.metrics.accuracy_score(tar_test, prediction)\n",
    "    \n",
    "#     \"Degree of Importance of Each Column\"\n",
    "#     model = ExtraTreesClassifier(n_estimators = 100) \n",
    "#     model.fit(pred_train, tar_train)\n",
    "#     imp = model.feature_importances_\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models = [\"NaiveBayes\", \"RandomForest\", \"DecisionTree\", \"LogisticRegression\", \"SVM\", \"KNeighborsClassifier\", \"XGBoost\", \"GradientBoost\", \"AdaBoost\"]\n",
    "performance_table = []\n",
    "for i in range(10):\n",
    "    scores = []\n",
    "    for model in models:\n",
    "        accuracy = ModelAccuracy(model)\n",
    "        scores.append(accuracy)\n",
    "    performance_table.append(scores)\n",
    "\n",
    "performance_table = pd.DataFrame(performance_table, columns = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.793296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.798883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.754190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.759777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NaiveBayes  RandomForest  DecisionTree  LogisticRegression       SVM  \\\n",
       "0    0.754190      0.843575      0.815642            0.832402  0.642458   \n",
       "1    0.731844      0.860335      0.765363            0.804469  0.603352   \n",
       "2    0.798883      0.787709      0.793296            0.832402  0.648045   \n",
       "3    0.737430      0.843575      0.782123            0.843575  0.675978   \n",
       "4    0.782123      0.787709      0.787709            0.793296  0.642458   \n",
       "5    0.776536      0.843575      0.776536            0.826816  0.625698   \n",
       "6    0.787709      0.810056      0.759777            0.837989  0.614525   \n",
       "7    0.754190      0.837989      0.748603            0.871508  0.614525   \n",
       "8    0.765363      0.837989      0.770950            0.832402  0.709497   \n",
       "9    0.754190      0.810056      0.765363            0.860335  0.614525   \n",
       "\n",
       "   KNeighborsClassifier   XGBoost  GradientBoost  AdaBoost  \n",
       "0              0.597765  0.815642       0.815642  0.782123  \n",
       "1              0.675978  0.832402       0.837989  0.821229  \n",
       "2              0.698324  0.888268       0.837989  0.821229  \n",
       "3              0.642458  0.798883       0.815642  0.793296  \n",
       "4              0.754190  0.793296       0.837989  0.821229  \n",
       "5              0.642458  0.849162       0.793296  0.815642  \n",
       "6              0.670391  0.871508       0.804469  0.798883  \n",
       "7              0.687151  0.776536       0.832402  0.754190  \n",
       "8              0.659218  0.782123       0.770950  0.782123  \n",
       "9              0.670391  0.843575       0.837989  0.759777  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764246</td>\n",
       "      <td>0.826257</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.833520</td>\n",
       "      <td>0.639106</td>\n",
       "      <td>0.669832</td>\n",
       "      <td>0.825140</td>\n",
       "      <td>0.818436</td>\n",
       "      <td>0.794972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.040922</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>0.025267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.754190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.828212</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.646648</td>\n",
       "      <td>0.794693</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.634078</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.824022</td>\n",
       "      <td>0.824022</td>\n",
       "      <td>0.796089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.780726</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.786313</td>\n",
       "      <td>0.842179</td>\n",
       "      <td>0.646648</td>\n",
       "      <td>0.684358</td>\n",
       "      <td>0.847765</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.819832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NaiveBayes  RandomForest  DecisionTree  LogisticRegression        SVM  \\\n",
       "count   10.000000     10.000000     10.000000           10.000000  10.000000   \n",
       "mean     0.764246      0.826257      0.776536            0.833520   0.639106   \n",
       "std      0.021844      0.025458      0.019172            0.023079   0.032809   \n",
       "min      0.731844      0.787709      0.748603            0.793296   0.603352   \n",
       "25%      0.754190      0.810056      0.765363            0.828212   0.614525   \n",
       "50%      0.759777      0.837989      0.773743            0.832402   0.634078   \n",
       "75%      0.780726      0.843575      0.786313            0.842179   0.646648   \n",
       "max      0.798883      0.860335      0.815642            0.871508   0.709497   \n",
       "\n",
       "       KNeighborsClassifier    XGBoost  GradientBoost   AdaBoost  \n",
       "count             10.000000  10.000000      10.000000  10.000000  \n",
       "mean               0.669832   0.825140       0.818436   0.794972  \n",
       "std                0.040922   0.038168       0.023147   0.025267  \n",
       "min                0.597765   0.776536       0.770950   0.754190  \n",
       "25%                0.646648   0.794693       0.807263   0.782123  \n",
       "50%                0.670391   0.824022       0.824022   0.796089  \n",
       "75%                0.684358   0.847765       0.837989   0.819832  \n",
       "max                0.754190   0.888268       0.837989   0.821229  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#위의 결과적으로 9개중에서 7개만 사용한다\n",
    "# SVM  KNeighborsClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100)\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred1 = classifier.predict(test)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred2 = classifier.predict(test)\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state = 100)\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred3 = classifier.predict(test)\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred4 = classifier.predict(test)\n",
    "\n",
    "classifier = LogisticRegression(solver = \"lbfgs\", max_iter = 700)\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred5 = classifier.predict(test)\n",
    "\n",
    "# classifier = SVC(gamma = \"scale\")\n",
    "# classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "# pred6 = classifier.predict(test)\n",
    "\n",
    "# classifier = KNeighborsClassifier(p = 2, n_neighbors = 10)\n",
    "# classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "# pred7 = classifier.predict(test)\n",
    "\n",
    "classifier = GradientBoostingClassifier(n_estimators = 7, learning_rate = 1.1)\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred8 = classifier.predict(test)\n",
    "\n",
    "classifier = AdaBoostClassifier(n_estimators = 50, learning_rate = 1)\n",
    "classifier.fit(train[list(test.columns)], train[\"Survived\"])\n",
    "pred9 = classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(list(zip(test_temp[\"PassengerId\"], pred1, pred2, pred3, pred4, pred5, pred8, pred9)))\n",
    "submit['Survived_Sum'] = submit.loc[:, 1:].sum( axis = 1)\n",
    "submit['Survived'] = np.where (submit['Survived_Sum'] > 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit.columns[0].name = 'PassengerId'\n",
    "submit.columns = ['PassengerId','p1','p2','p3', 'p4', 'p5', 'p8', 'p9', 'Survived_Sum', 'Survived']\n",
    "submit2 = submit[['PassengerId', 'Survived']]\n",
    "submit2.to_csv('submissio7Model.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
