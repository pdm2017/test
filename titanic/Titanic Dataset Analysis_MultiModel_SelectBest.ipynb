{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train2.csv\")\n",
    "test = pd.read_csv(\"../data/test2.csv\")\n",
    "test_temp = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelAccuracy(model):\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(train[list(test.columns)], train[\"Survived\"], test_size = 0.2)\n",
    "    \n",
    "    if model == \"NaiveBayes\":\n",
    "        classifier = GaussianNB()\n",
    "    elif model == \"RandomForest\":\n",
    "        classifier = RandomForestClassifier(n_estimators = 100)\n",
    "    elif model == \"DecisionTree\":\n",
    "        classifier = DecisionTreeClassifier(random_state = 100)\n",
    "    elif model == \"XGBoost\":\n",
    "        classifier = XGBClassifier()\n",
    "    elif model == \"LogisticRegression\":\n",
    "        classifier = LogisticRegression(solver = \"lbfgs\", max_iter = 700)\n",
    "    elif model == \"SVM\":\n",
    "        classifier = SVC(gamma = \"scale\")\n",
    "    elif model == \"KNeighborsClassifier\":\n",
    "        classifier = KNeighborsClassifier(p = 2, n_neighbors = 10)\n",
    "    elif model == \"GradientBoost\":\n",
    "        classifier = GradientBoostingClassifier(n_estimators = 7, learning_rate = 1.1)\n",
    "    elif model == \"AdaBoost\":\n",
    "        classifier = AdaBoostClassifier(n_estimators = 50, learning_rate = 1)\n",
    "\n",
    "    classifier.fit(pred_train, tar_train)\n",
    "    prediction = classifier.predict(pred_test)\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(tar_test, prediction)\n",
    "    accuracy = sklearn.metrics.accuracy_score(tar_test, prediction)\n",
    "    \n",
    "#     \"Degree of Importance of Each Column\"\n",
    "#     model = ExtraTreesClassifier(n_estimators = 100) \n",
    "#     model.fit(pred_train, tar_train)\n",
    "#     imp = model.feature_importances_\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models = [\"NaiveBayes\", \"RandomForest\", \"DecisionTree\", \"LogisticRegression\", \"SVM\", \"KNeighborsClassifier\", \"XGBoost\", \"GradientBoost\", \"AdaBoost\"]\n",
    "performance_table = []\n",
    "for i in range(10):\n",
    "    scores = []\n",
    "    for model in models:\n",
    "        accuracy = ModelAccuracy(model)\n",
    "        scores.append(accuracy)\n",
    "    performance_table.append(scores)\n",
    "\n",
    "performance_table = pd.DataFrame(performance_table, columns = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.778212</td>\n",
       "      <td>0.824022</td>\n",
       "      <td>0.781006</td>\n",
       "      <td>0.834637</td>\n",
       "      <td>0.643575</td>\n",
       "      <td>0.670950</td>\n",
       "      <td>0.827374</td>\n",
       "      <td>0.801676</td>\n",
       "      <td>0.816760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033834</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>0.025233</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.031077</td>\n",
       "      <td>0.027970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.776536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.755587</td>\n",
       "      <td>0.812849</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.822626</td>\n",
       "      <td>0.615922</td>\n",
       "      <td>0.655028</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.790503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.829609</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.829609</td>\n",
       "      <td>0.796089</td>\n",
       "      <td>0.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.803073</td>\n",
       "      <td>0.842179</td>\n",
       "      <td>0.797486</td>\n",
       "      <td>0.850559</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>0.844972</td>\n",
       "      <td>0.803073</td>\n",
       "      <td>0.836592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NaiveBayes  RandomForest  DecisionTree  LogisticRegression        SVM  \\\n",
       "count   10.000000     10.000000     10.000000           10.000000  10.000000   \n",
       "mean     0.778212      0.824022      0.781006            0.834637   0.643575   \n",
       "std      0.033834      0.026104      0.025233            0.022222   0.031690   \n",
       "min      0.709497      0.776536      0.737430            0.798883   0.608939   \n",
       "25%      0.755587      0.812849      0.759777            0.822626   0.615922   \n",
       "50%      0.787709      0.829609      0.787709            0.826816   0.642458   \n",
       "75%      0.803073      0.842179      0.797486            0.850559   0.659218   \n",
       "max      0.821229      0.860335      0.815642            0.877095   0.703911   \n",
       "\n",
       "       KNeighborsClassifier    XGBoost  GradientBoost   AdaBoost  \n",
       "count             10.000000  10.000000      10.000000  10.000000  \n",
       "mean               0.670950   0.827374       0.801676   0.816760  \n",
       "std                0.030309   0.022875       0.031077   0.027970  \n",
       "min                0.620112   0.776536       0.770950   0.776536  \n",
       "25%                0.655028   0.821229       0.787709   0.790503  \n",
       "50%                0.659218   0.829609       0.796089   0.826816  \n",
       "75%                0.695531   0.844972       0.803073   0.836592  \n",
       "max                0.715084   0.854749       0.877095   0.854749  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[list(test.columns)], train[\"Survived\"], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_...\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7, 1], 'gamma': [0],\n",
       "                         'learning_rate': [0.001], 'max_depth': [4],\n",
       "                         'min_child_weight': [0, 1], 'n_estimators': [10, 2500],\n",
       "                         'reg_alpha': [0, 6e-05], 'scale_pos_weight': [1],\n",
       "                         'seed': [27], 'subsample': [0.7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결국 최고의 하나만 선택한다\n",
    "# 그리고 Hyper Parameter Tuning의 실행 필요\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"max_depth\":[3,5,8],\n",
    "#     \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "#     \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "#     \"n_estimators\":[10]\n",
    "#     }\n",
    "\n",
    "# model = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n",
    "#                                 max_depth=4, min_child_weight=0,\n",
    "#                                 gamma=0, subsample=0.7,\n",
    "#                                 colsample_bytree=0.7,\n",
    "#                                 scale_pos_weight=1, seed=27,\n",
    "#                                 reg_alpha=0.00006)\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate':[0.001],\n",
    "    'n_estimators':[10,2500],\n",
    "    'max_depth':[4], \n",
    "    'min_child_weight':[0, 1],\n",
    "    'gamma':[0], \n",
    "    'subsample':[0.7],\n",
    "    'colsample_bytree':[0.7, 1],\n",
    "    'scale_pos_weight':[1], \n",
    "    'seed':[27],\n",
    "    'reg_alpha':[0, 0.00006]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(XGBClassifier(), parameters, cv=10, n_jobs=-1)\n",
    "\n",
    "#여기가 엄청 오래걸린다\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8806179775280899\n",
      "{'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.001, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 2500, 'reg_alpha': 0, 'scale_pos_weight': 1, 'seed': 27, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.8553370786516854\n",
      "Accuracy =  0.7988826815642458\n",
      "Score =  0.8806179775280899\n",
      "Accuracy =  0.8379888268156425\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                                     colsample_bylevel=1, colsample_bynode=1,\n",
    "                                     colsample_bytree=1, gamma=0,\n",
    "                                     learning_rate=0.001, max_delta_step=0,\n",
    "                                     max_depth=4, min_child_weight=1,\n",
    "                                     missing=None, n_estimators=10, n_jobs=1,\n",
    "                                     nthread=None, objective='binary:logistic',\n",
    "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "                                     scale_pos_weight=1, seed=None, silent=None,\n",
    "                                     subsample=0.7, verbosity=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Score = ', model.score(X_train, y_train))\n",
    "print('Accuracy = ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "model2 = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n",
    "                                max_depth=4, min_child_weight=0,\n",
    "                                gamma=0, subsample=0.7,\n",
    "                                colsample_bytree=0.7,\n",
    "                                scale_pos_weight=1, seed=27,\n",
    "                                reg_alpha=0.00006)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "print('Score = ', model2.score(X_train, y_train))\n",
    "print('Accuracy = ', accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(list(zip(test_temp[\"PassengerId\"], pred)), columns = ['PassengerId', 'Survived'])\n",
    "submit.to_csv('submissioBestNoduleHT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
